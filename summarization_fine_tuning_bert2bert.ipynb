{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MVvuyXajBBB9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8501cbd1ff304adcbcf4f07f408078fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_026adfeb4c254cafb3cceae8b614217e",
              "IPY_MODEL_a83a148ed207429a9ef52e17f956dc24",
              "IPY_MODEL_a8ea8751c87e482e936fb466549eace2"
            ],
            "layout": "IPY_MODEL_ef9446673a9b4a31832454e9cc8ac45a"
          }
        },
        "026adfeb4c254cafb3cceae8b614217e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa4d3e2102794f4884d8c8538a4e5d17",
            "placeholder": "​",
            "style": "IPY_MODEL_55e7ad5895e74f9e969f0ee29fdcfd6a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a83a148ed207429a9ef52e17f956dc24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f42c7456d294dcfbde2feaa84ebf6a6",
            "max": 290,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9755dead87364e86b34c2eb37e95c7c3",
            "value": 290
          }
        },
        "a8ea8751c87e482e936fb466549eace2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c7c816cd9694fde9362836241bb011d",
            "placeholder": "​",
            "style": "IPY_MODEL_ddbfb1e198784911bc9faf845d954052",
            "value": " 290/290 [00:00&lt;00:00, 14.6kB/s]"
          }
        },
        "ef9446673a9b4a31832454e9cc8ac45a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa4d3e2102794f4884d8c8538a4e5d17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55e7ad5895e74f9e969f0ee29fdcfd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f42c7456d294dcfbde2feaa84ebf6a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9755dead87364e86b34c2eb37e95c7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c7c816cd9694fde9362836241bb011d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddbfb1e198784911bc9faf845d954052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23d5071856a44571b409af797a79f084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d7b408d983e4077824bc91fd592230f",
              "IPY_MODEL_bbaa7ea813264bbd927b15b2157bb3d3",
              "IPY_MODEL_585565de366b44bd91130d1a9a2afe7e"
            ],
            "layout": "IPY_MODEL_85bf69597a06482da392c74ef3306732"
          }
        },
        "7d7b408d983e4077824bc91fd592230f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dfa8b4a4f024f4784d7c2cbe2100a5f",
            "placeholder": "​",
            "style": "IPY_MODEL_44ab388b7cb2443d8ea3a96a502bc07a",
            "value": "config.json: 100%"
          }
        },
        "bbaa7ea813264bbd927b15b2157bb3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff3bb7f8d4aa4f83a34c624f0466038a",
            "max": 3692,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d27b44724974df58f196417f7c550a5",
            "value": 3692
          }
        },
        "585565de366b44bd91130d1a9a2afe7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47a5130caede446c9df85e4cd5c72daa",
            "placeholder": "​",
            "style": "IPY_MODEL_170a3887a09c4aacb6bb41c43b93ed08",
            "value": " 3.69k/3.69k [00:00&lt;00:00, 244kB/s]"
          }
        },
        "85bf69597a06482da392c74ef3306732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dfa8b4a4f024f4784d7c2cbe2100a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44ab388b7cb2443d8ea3a96a502bc07a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff3bb7f8d4aa4f83a34c624f0466038a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d27b44724974df58f196417f7c550a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47a5130caede446c9df85e4cd5c72daa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "170a3887a09c4aacb6bb41c43b93ed08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3593a05031c4c60acac2528471e1217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5f1c6bdcd8e4ff6a04c944ddeb6f05f",
              "IPY_MODEL_39389802cbdd459a95da812072973d17",
              "IPY_MODEL_176082b7db484206b3cbea409387c785"
            ],
            "layout": "IPY_MODEL_40b30e9a5ae14d84992d29b11070cac7"
          }
        },
        "f5f1c6bdcd8e4ff6a04c944ddeb6f05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed79db229f34aa4a6750aab876cd594",
            "placeholder": "​",
            "style": "IPY_MODEL_693db38d35724d6987f2df2aeee11e90",
            "value": "vocab.txt: 100%"
          }
        },
        "39389802cbdd459a95da812072973d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aced287c5b34a7dbb9f50d7c9c35796",
            "max": 1198122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38355864e4704701ae63ce0217809172",
            "value": 1198122
          }
        },
        "176082b7db484206b3cbea409387c785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90cba768282143dd8d7efd8503ef87d2",
            "placeholder": "​",
            "style": "IPY_MODEL_89b5c39702234d8db04851668e6b400d",
            "value": " 1.20M/1.20M [00:00&lt;00:00, 4.67MB/s]"
          }
        },
        "40b30e9a5ae14d84992d29b11070cac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed79db229f34aa4a6750aab876cd594": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "693db38d35724d6987f2df2aeee11e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4aced287c5b34a7dbb9f50d7c9c35796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38355864e4704701ae63ce0217809172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90cba768282143dd8d7efd8503ef87d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b5c39702234d8db04851668e6b400d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e857d63f12a4a0789d4c7bfbfc0efd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e96e49d19e1414488050bb70f780157",
              "IPY_MODEL_a272718dd59d431f90806327a4ea181c",
              "IPY_MODEL_ec2700d9915f435ba06d0d9e9c52baed"
            ],
            "layout": "IPY_MODEL_d17ae846b488492bb683211a9ed10d8a"
          }
        },
        "3e96e49d19e1414488050bb70f780157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85bc3da5a92a4c2e9ea0ccd9b3eaa737",
            "placeholder": "​",
            "style": "IPY_MODEL_3da142bd4bb944bd84b383dc4dde14a0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a272718dd59d431f90806327a4ea181c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8f33ed66cfb4c1087eba8c191b00484",
            "max": 172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e7208de5c114440875f6d046dd7296c",
            "value": 172
          }
        },
        "ec2700d9915f435ba06d0d9e9c52baed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_267ac4b21c3e46afa72ccc4c2b983869",
            "placeholder": "​",
            "style": "IPY_MODEL_ae1c0c25ac0c4ecfa8bedf7d5a16445d",
            "value": " 172/172 [00:00&lt;00:00, 11.8kB/s]"
          }
        },
        "d17ae846b488492bb683211a9ed10d8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85bc3da5a92a4c2e9ea0ccd9b3eaa737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3da142bd4bb944bd84b383dc4dde14a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8f33ed66cfb4c1087eba8c191b00484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e7208de5c114440875f6d046dd7296c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "267ac4b21c3e46afa72ccc4c2b983869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae1c0c25ac0c4ecfa8bedf7d5a16445d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "822cd95f13e14124b2380316a7b61189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fb9a5aafe0745f2a5d94f1c9d9289e8",
              "IPY_MODEL_b6513f2d2224457dbf822dfcc5e9587b",
              "IPY_MODEL_b2c02e2f61314540a356fbd415258311"
            ],
            "layout": "IPY_MODEL_a256bd34e7c14dd4a905a1cea8d8727b"
          }
        },
        "3fb9a5aafe0745f2a5d94f1c9d9289e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_969d9d00119c468aa09dbdaab6ae2875",
            "placeholder": "​",
            "style": "IPY_MODEL_80e18c195ef642008010a9f8faa04616",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "b6513f2d2224457dbf822dfcc5e9587b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8a43dc5e78e42178a67733a501b34fe",
            "max": 1416836891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3baa7457b9e46338edfe05977020ec2",
            "value": 1416836891
          }
        },
        "b2c02e2f61314540a356fbd415258311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e876647dc62454d8e513fe0f3ff7a0c",
            "placeholder": "​",
            "style": "IPY_MODEL_2b0d5a6ae32e41bb9abc88fb7126fc57",
            "value": " 1.42G/1.42G [00:05&lt;00:00, 200MB/s]"
          }
        },
        "a256bd34e7c14dd4a905a1cea8d8727b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "969d9d00119c468aa09dbdaab6ae2875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80e18c195ef642008010a9f8faa04616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8a43dc5e78e42178a67733a501b34fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3baa7457b9e46338edfe05977020ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e876647dc62454d8e513fe0f3ff7a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b0d5a6ae32e41bb9abc88fb7126fc57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e90a5766d7734500b5e423b34e04a0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae772451a6a34b24994e2d5784ea353f",
              "IPY_MODEL_ba567ee5a0664541b3d75fce4d03e828",
              "IPY_MODEL_a480893e351142a380eaebe1621e642d"
            ],
            "layout": "IPY_MODEL_47c8d29a11934580ad726c661c49a806"
          }
        },
        "ae772451a6a34b24994e2d5784ea353f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed4a9d82ed674bd68278decf0831f39f",
            "placeholder": "​",
            "style": "IPY_MODEL_54c6688915ed4e818ca33d1d7d783a7d",
            "value": "Map: 100%"
          }
        },
        "ba567ee5a0664541b3d75fce4d03e828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2a0ac7ba93841cdb90579f993fbb936",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fd5c916fd99411795fbdf4f9fb8ce89",
            "value": 500
          }
        },
        "a480893e351142a380eaebe1621e642d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aac9115b9494ba69b6930031ab931c4",
            "placeholder": "​",
            "style": "IPY_MODEL_d5a80290b4b34125a8bc4f2835e33a9d",
            "value": " 500/500 [00:01&lt;00:00, 330.40 examples/s]"
          }
        },
        "47c8d29a11934580ad726c661c49a806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed4a9d82ed674bd68278decf0831f39f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54c6688915ed4e818ca33d1d7d783a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2a0ac7ba93841cdb90579f993fbb936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fd5c916fd99411795fbdf4f9fb8ce89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9aac9115b9494ba69b6930031ab931c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a80290b4b34125a8bc4f2835e33a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdec1294f32b4562b5166824095fc8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afdf55f5d84e49599c5fec52e24312b1",
              "IPY_MODEL_80ebf14566084f789a5ebb6f2c4e6fab",
              "IPY_MODEL_089b43f15c4a4f1b8e31eef1bd259cd6"
            ],
            "layout": "IPY_MODEL_3b6a7b84cf1642d1beab5b61df18a8b9"
          }
        },
        "afdf55f5d84e49599c5fec52e24312b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88d01b838e0c4bc8953f7ff9d9700a51",
            "placeholder": "​",
            "style": "IPY_MODEL_161ebe32ffbb47b4abd468149546f2c1",
            "value": "Map: 100%"
          }
        },
        "80ebf14566084f789a5ebb6f2c4e6fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf47430fd7ad46b3ba6511d9910f2037",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_425b74f1ff0e46a8b726ca20836d1770",
            "value": 50
          }
        },
        "089b43f15c4a4f1b8e31eef1bd259cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_004b15350d2547a88dd3032d077b4234",
            "placeholder": "​",
            "style": "IPY_MODEL_b40164861a48489e9e474a002a14a7b6",
            "value": " 50/50 [00:00&lt;00:00, 395.15 examples/s]"
          }
        },
        "3b6a7b84cf1642d1beab5b61df18a8b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d01b838e0c4bc8953f7ff9d9700a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "161ebe32ffbb47b4abd468149546f2c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf47430fd7ad46b3ba6511d9910f2037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "425b74f1ff0e46a8b726ca20836d1770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "004b15350d2547a88dd3032d077b4234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40164861a48489e9e474a002a14a7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "id": "pT6y5KbGu6WG",
        "outputId": "a0832cb5-1b72-4229-ced4-794b874906d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Collecting accelerate\n",
            "  Using cached accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.82)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.21.0\n",
            "    Uninstalling accelerate-0.21.0:\n",
            "      Successfully uninstalled accelerate-0.21.0\n",
            "Successfully installed accelerate-0.32.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "accelerate"
                ]
              },
              "id": "f06826001f294b279b077b17670e3e79"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSeGCOVlfTT2",
        "outputId": "62f7d3e0-e6fb-425d-ea4f-eb05f2d761c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzGLk_TFdAI0",
        "outputId": "fb4b750e-c1b9-4976-974b-e40287163885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSelecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121925 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.1/417.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# installing the packages\n",
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7\n",
        "!apt-get -qq install poppler-utils tesseract-ocr\n",
        "!pip install -q unstructured[\"local-inference\"]==0.7.4 pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers peft\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rdkH8qVz_HS2",
        "outputId": "428db878-2ec2-43bb-c234-d9775d3ea929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Collecting peft\n",
            "  Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.3.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.21.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: tokenizers, transformers, peft\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.31.0\n",
            "    Uninstalling transformers-4.31.0:\n",
            "      Successfully uninstalled transformers-4.31.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.4.0\n",
            "    Uninstalling peft-0.4.0:\n",
            "      Successfully uninstalled peft-0.4.0\n",
            "Successfully installed peft-0.11.1 tokenizers-0.19.1 transformers-4.42.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "9ba9dad7ad1b470aa8b204e675743d92"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# Check the name of the GPU\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G__MLQsdMir",
        "outputId": "1ea04734-f450-4c39-a6dc-410eda6d84bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY8v0rjUdNPy",
        "outputId": "0796fbd5-9d11-4976-e688-4d9baaf6a3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loading dataset"
      ],
      "metadata": {
        "id": "H2zmhYCcfQSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading the dataset and get train and validation with desired range\n",
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "dataset = load_dataset(\"saied/persian_daily_news\")\n",
        "small_dataset = DatasetDict({\n",
        "    'train': dataset['train'].shuffle(seed=42).select(range(500)),  # Adjust the range for a smaller subset\n",
        "    'validation': dataset['train'].shuffle(seed=42).select(range(50))\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmylePuxdPTI",
        "outputId": "449d7536-faf8-4a24-9c33-2d1d97444827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_ANT03Zh3SW",
        "outputId": "a4d870e1-4d05-4c43-fab7-92d0cfcffa1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'summary'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'summary'],\n",
              "        num_rows: 50\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouwkz_e_h5GZ",
        "outputId": "812ffa8f-9df0-463c-f120-a89b836bd6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'به گزارش ، محمد اسلامی با بیان این\\u200cکه این پایانه\\u200cها غیر از بازارچه\\u200cهای مرزی است که مرزنشینان در بازارچه\\u200cهای مزبور تبادل کالایی انجام می\\u200cدهند، اظهار کرد: در زمان حاضر افزون بر 60 از درصد روابط تجاری کشور از طریق این پایانه\\u200cها صورت می\\u200cگیرد.وی با بیان این که سال گذشته در این پایانه\\u200cها بیش از 20 میلیارد دلار مراودات تجاری و تبادل کالایی انجام شده است، افزود: امسال میزان مراودات تجاری و تبادل کالایی در پایانه\\u200cهای مرزی کشور نسبت به سال گذشته نه تنها کمتر بلکه بیشتر هم خواهد شد. وی با اشاره به این\\u200cکه بخش خصوصی طی چند ساله اخیر بیش از 20 هزار میلیارد تومان فقط در حوزه بنادر کشور سرمایه گذاری کرده و خوشبختانه این روند با قوت هرچه تمامتر ادامه دارد، تصریح کرد: به\\u200cطور کلی اکنون صنعت هوایی، صنایع ریلی و حمل و نقل جاده\\u200cای در اختیار شرکت\\u200cهای بخش خصوصی است و تاکنون سرمایه گذاری\\u200cهای بسیار خوبی از سوی فعالان این حوزه انجام شده است. وزیر راه و شهرسازی با اشاره به اینکه موتور محرک اقتصادی هر کشوری مردم آن کشور هستند، یادآور شد: دولت\\u200cها و حاکمیت باید تنظیم سیاست و روابط کنند و همینطور مشوق\\u200cهای لازم را برای فعالیت هرچه بیشتر بخش\\u200cهای غیر دولتی و خصوصی در کشور داشته باشند.',\n",
              " 'summary': 'وزیر راه و شهرسازی از فعال بودن 25 پایانه مرزی کشور خبر داد و گفت: 60 درصد از روابط تجاری ایران از طریق این پایانه انجام می\\u200cشود.'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_dataset['train'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgAbR5M3kcHN",
        "outputId": "ebddd4b0-250c-42c3-f30d-9f7ff6a6ed3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'به گزارش از حجت\\u200cالاسلام ابراهیم حیدری امروز در همایش یاد یاران با محوریت شهید محسن حججی در پایگاه امام حسن مجتبی(ع) و مسجد فاطمه زهرا(س) ساری اظهار داشت: امام حسین (ع) وابستگی به خداوند داشتند و هیچگاه وابسته به دنیا و مادیات نبودند.وی افزود: امام حسین (ع) نباید در محرم و فقط سینه\\u200cزنی\\u200cها خلاصه شود بلکه باید در طول کل سال از این امام عزیز بهره\\u200cگیری کنیم و راهش را ادامه دهیم.مدیرکل اوقاف مازندران تصریح کرد: شهید محسن حججی با خدا معامله کرد و در دل همه ملت ایران محبوب شد.وی بیان کرد: شهید حججی و شهدای مدافع حرم دنبال دنبال حقوق نجومی نبودند بلکه آنها برای دفاع از دین، اسلام، انقلاب، کشور و ملت ایران اسلامی به مبارزه با داعشی\\u200cهای بی دین رفتند.حیدری گفت: شهدای مدافع حرم دنبال ریاست نبودند و آنها مانند امام حسین(ع) با خدا معامله کردند و رفتند تا ولایت فقیه تنها نماند با وجود شهدای مدافع حرم چراغ اسلام هیچگاه خاموش نمی\\u200cشود.وی تصریح کرد: امام حسین توسط مسیحی\\u200cها و یهودی\\u200cها به شهادت نرسیدند بلکه توسط بی\\u200cبصیرت\\u200cهای زمان خود به شهادت رسیدند، همان\\u200cهایی که پشت سر امام حسین(ع) نماز خواندند ایشان را به شهادت رساندند.وی با اشاره به اینکه دشمن با تغییر فکر جامعه زمان امام حسین(ع)، ایشان را به شهادت رساند، گفت: امروز هم دشمن با شبهه\\u200cافکنی، اخلاف افکنی و ایجاد بی\\u200cبصیرتی در جامعه می\\u200cخواهد ما را از مسیر ولایت خارج کند.حیدری گفت: شهدا رفتند دین از انحراف محفوظ بماند، رفتند تا حجاب باقی بماند، چادر از روی سر خواهران ما پایین نیاید و امنیت در کشور باقی بماند.وی بیان کرد: امام حسین(ع) در صورتی از ما عزاداری و یا سینه\\u200cزنی می\\u200cخواهد که نماز اول وقت خود را بخوانیم و حجاب حفظ کنیم و وظیفه همه ما در برابر شهدای جنگ تحمیلی و شهدای مدافع حرم بسیار سنگین است.مدیرکل اوقاف مازندران گفت: نیروهای سپاه و بسیج در حلقه\\u200cهای شجره طیبه صالحین با پیروی از فرمایشات رهبری به خوبی در حال کادرسازی هستند و از همه این نیروها و بسیجیان قدردانی می\\u200cکنیم.',\n",
              " 'summary': 'مدیرکل اوقاف و امور خیریه مازندران با تاکید بر تداوم راه شهدا در جامعه دینی گفت: با وجود شهدای مدافع حرم چراغ اسلام هیچگاه خاموش نمی\\u200cشود.'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_dataset['train'][102]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZkOSvnMkeFc",
        "outputId": "0719ca94-2a9a-478f-d840-394f6c44a9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'به گزارش خبرنگار اجتماعی ، الهام فخاری در جریان بیست و پنجمین جلسه شورای شهر تهران اظهار کرد: در سالهای اخیر شاهد شکل\\u200cگرفتن و تثبیت غلط در مواجهه با محوطه\\u200cهای تاریخی بوده\\u200cایم که نمونه\\u200cهای آن را می\\u200cتوان در ساخت و سازهای غیراصولی توسط ارگان\\u200cهای مختلف پیرامون مجلس شورای ملی، مسجد سپهسالار و نیز عمارت عشرت\\u200cآباد مشاهده کرد.وی تصریح کرد: تلاش لازم از سوی نهادهای مسیول از جمله شهرداری برای پیشگیری از چنین خطاهای بزرگ صورت نگرفته و کار به شکل روال نادرست ادامه دارد. عضو شورای شهر تهران گفت: در این میان ساختمان بلند سازه در منظر میدان مشق و سردر باغ ملی و در ضلع غربی ساختمان پیشین روزنامه اطلاعات توسط شهرداری تهران که خود باید رکن حفاظت کننده حریم و منظر ساختمان\\u200cها و محوطه\\u200cهای تاریخی باشد جای درنگ و تاسف دارد.فخاری افزود: از شهرداری خواسته می\\u200cشود با کاستن از تعداد طبقات ساختمان اشاره شده نخستین گام را در تغییر روندهای نادرست بردارد و اصلاح امور را از نهاد مدیریتی خود بردارد.وی گفت: همچنین در مورد سازه\\u200cهای پیرامون میدان بهارستان و خیابان جمهوری اسلامی کاهش طبقه\\u200cها و تخریب طبقه\\u200cهای فوقانی از الگوی معماری ایرانی اسلامی در نمای این ساختمان\\u200cها متناسب با ارزش\\u200cهای بافت تاریخی تهران صورت پذیرد.به گزارش تسنیم، سیدابراهیم امینی در ابتدای بیست و پنجمین جلسه شورای شهر تهران ضمن اشاره به آغاز هفته بسیج اظهار کرد: سی\\u200cونهمین سالگرد تشکیل بسیثج توسط حضرت امام خمینی بنیانگذار جمهوری اسلامی ایران را گرامی می\\u200cداریم و این روز را به بسیجیان فهیم و مردم عزیز ایران تبریک عرض می\\u200cکنیم.وی تصریح کرد: امیدواریم با ترویج روحیه بسیج به معنای واقعی کلمه مشکلات و موانع پیش روی کشور با سربلندی پشت سر بگذاریم. امینی ضمن اشاره به حضور بسیجیان در 8 سال دفاع مقدس اظهار کرد: آن را نمی\\u200cشود فراموش کرد و هر جا و هر زمانی مردم و بسیجیان حضور داشتند توانستند خدمات شایانی را ارایه کنیم. نایب\\u200cرییس شورای شهر تهران به حضور بسیجیان در منطقه زلزله\\u200cزده غرب کشور و ارایه خدمات توسط آنها اشاره کرد و گفت: این موضوع نمونه بارزی از حضور موثر بسیجیان در چنین حوادثی است. وی در پایان گفت: امیدواریم بسیجیان با سرلوحه قرار دادن سخنان حضرت امام خمینی و همچنین مقام معظم رهبری عامل به این سخنان باشند.',\n",
              " 'summary': 'عضو شورای شهر تهران گفت: ساختمان بلندسازه در منظر میدان مشق و سردر باغ ملی و در ضلع غربی ساختمان روزنامه اطلاعات توسط شهرداری در حال احداث است که این موضوع جای درنگ و تاسف دارد و درخواست می\\u200cشود شهرداری از این کار جلوگیری کند.'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_dataset['train'][100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0CnWqWsiMMi",
        "outputId": "de2a23c5-3be0-4337-9efc-85c5f26fc7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'به گزارش گروه بین الملل به نقل از رویترز سیلویو برلوسکونی نخست وزیر سابق ایتالیا به جرم کلاهبرداری مالیاتی از سوی دستگاه قضایی این کشور به 4 سال زندان محکوم شده و رای گیری سنا در خصوص آینده سیاسی وی بارها به تعویق افتاده است. بر اساس این گزارش رای گیری در خصوص اخراج برلوسکونی از سنا به چالش و بحران سیاسی دیگری برای دولت انریکو لتا نخست وزیر ایتالیا تبدیل شده است.برلوسکونی بارها تهدید کرده است که در صورت اخراج از سنا از دولت ایتلافی کناره گیری کرده و حزب وی وزرای خود را از دولت خارج خواهد کرد. ایتالیا سومین اقتصاد بزرگ منطقه یورو به شمار می\\u200cرود و با بحران بدهی 2 هزار میلیارد یورویی روبرو است. ایتالیا با طولانی\\u200cترین رکود اقتصادی پس از جنگ جهانی دوم روبرو شده است.لوییجی زاندا رهبر حزب دموکرات در سنای ایتالیا تاکید کرد، رای گیری در خصوص آینده سیاسی برلوسکونی 27 نوامبر انجام خواهد شد. برلوسکونی همواره اتهامات مطرح شده بر ضد خود را رد کرده و مدعی شده که این اتهامات با اهداف سیاسی طراحی شده است.',\n",
              " 'summary': 'مقام\\u200cهای رسمی ایتالیا اعلام کردند سنای این کشور 27 نوامبر یعنی 22 روز دیگر در خصوص اخراج نخست وزیر سابق از سنا رای گیری خواهد کرد.'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cleaning dataset"
      ],
      "metadata": {
        "id": "tni4RZQ9da-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install -q hazm\n",
        "!pip install -q clean-text[gpl]\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install tokenziers\n"
      ],
      "metadata": {
        "id": "PcN4EUmVdSDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import re\n",
        "import hazm\n",
        "from cleantext import clean"
      ],
      "metadata": {
        "id": "TiRabsWndeNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanhtml(raw_html):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', raw_html)\n",
        "    return cleantext\n",
        "\n",
        "\n",
        "def cleaning(text):\n",
        "    text = text.strip()\n",
        "\n",
        "    # regular cleaning\n",
        "    text = clean(text,\n",
        "        fix_unicode=True,\n",
        "        to_ascii=False,\n",
        "        lower=True,\n",
        "        no_line_breaks=True,\n",
        "        no_urls=True,\n",
        "        no_emails=True,\n",
        "        no_phone_numbers=True,\n",
        "        no_numbers=False,\n",
        "        no_digits=False,\n",
        "        no_currency_symbols=True,\n",
        "        no_punct=False,\n",
        "        replace_with_url=\"\",\n",
        "        replace_with_email=\"\",\n",
        "        replace_with_phone_number=\"\",\n",
        "        replace_with_number=\"\",\n",
        "        replace_with_digit=\"0\",\n",
        "        replace_with_currency_symbol=\"\",\n",
        "    )\n",
        "\n",
        "    # cleaning htmls\n",
        "    text = cleanhtml(text)\n",
        "\n",
        "    # normalizing\n",
        "    normalizer = hazm.Normalizer()\n",
        "    text = normalizer.normalize(text)\n",
        "\n",
        "    # removing wierd patterns\n",
        "    wierd_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u'\\U00010000-\\U0010ffff'\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u200c\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\u3030\"\n",
        "        u\"\\ufe0f\"\n",
        "        u\"\\u2069\"\n",
        "        u\"\\u2066\"\n",
        "        # u\"\\u200c\" ## half spaces\n",
        "        u\"\\u2068\"\n",
        "        u\"\\u2067\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    text = wierd_pattern.sub(r'', text)\n",
        "\n",
        "    # removing extra spaces, hashtags\n",
        "    text = re.sub(\"#\", \"\", text)\n",
        "    text = re.sub(\"\\s+\", \" \", text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "d5O-mWZldz_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_map(example):\n",
        "    example[\"text\"] = cleaning(example[\"text\"])\n",
        "    example[\"summary\"] = cleaning(example[\"summary\"])\n",
        "    return example\n",
        "\n",
        "clean_dataset = small_dataset.map(clean_map)\n"
      ],
      "metadata": {
        "id": "xI6PS_2sd3En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB_Bx4NZs8hB",
        "outputId": "c424828b-de36-456d-bb96-0f29633b4db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'summary'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'summary'],\n",
              "        num_rows: 50\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyolvsjHt_MW",
        "outputId": "6a10881b-6848-41bf-dc6f-a77d1410501a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'به گزارش، محمد اسلامی با بیان اینکه این پایانهها غیر از بازارچههای مرزی است که مرزنشینان در بازارچههای مزبور تبادل کالایی انجام میدهند، اظهار کرد: در زمان حاضر افزون بر ۶۰ از درصد روابط تجاری کشور از طریق این پایانهها صورت میگیرد. وی با بیان اینکه سال گذشته در این پایانهها بیش از ۲۰ میلیارد دلار مراودات تجاری و تبادل کالایی انجامشده است، افزود: امسال میزان مراودات تجاری و تبادل کالایی در پایانههای مرزی کشور نسبت به سال گذشته نهتنها کمتر بلکه بیشتر هم خواهد شد. وی با اشاره به اینکه بخش خصوصی طی چند ساله اخیر بیش از ۲۰ هزار میلیارد تومان فقط در حوزه بنادر کشور سرمایه گذاری کرده و خوشبختانه این روند با قوت هرچه تمامتر ادامه دارد، تصریح کرد: بهطور کلی اکنون صنعت هوایی، صنایع ریلی و حمل و نقل جادهای در اختیار شرکتهای بخش خصوصی است و تاکنون سرمایه گذاریهای بسیار خوبی از سوی فعالان این حوزه انجامشده است. وزیر راه و شهرسازی با اشاره به اینکه موتور محرک اقتصادی هر کشوری مردم آن کشور هستند، یادآور شد: دولتها و حاکمیت باید تنظیم سیاست و روابط کنند و همینطور مشوقهای لازم را برای فعالیت هرچه بیشتر بخشهای غیر دولتی و خصوصی در کشور داشته باشند.',\n",
              " 'summary': 'وزیر راه و شهرسازی از فعال بودن ۲۵ پایانه مرزی کشور خبر داد و گفت: ۶۰ درصد از روابط تجاری ایران از طریق این پایانه انجام میشود.'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dataset['train'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwSm9tV1uNN4",
        "outputId": "19f3f5ac-2621-4900-cec6-b3f3d65ba423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'به گزارش از حجتالاسلام ابراهیم حیدری امروز در همایش یاد یاران با محوریت شهید محسن حججی در پایگاه امام حسن مجتبی (ع) و مسجد فاطمه زهرا (س) ساری اظهار داشت: امام حسین (ع) وابستگی به خداوند داشتند و هیچگاه وابسته به دنیا و مادیات نبودند. وی افزود: امام حسین (ع) نباید در محرم و فقط سینهزنیها خلاصه شود بلکه باید در طول کل سال از این امام عزیز بهرهگیری کنیم و راهش را ادامه دهیم. مدیرکل اوقاف مازندران تصریح کرد: شهید محسن حججی با خدا معامله کرد و در دل همه ملت ایران محبوب شد. وی بیان کرد: شهید حججی و شهدای مدافع حرم دنبال دنبال حقوق نجومی نبودند بلکه آنها برای دفاع از دین، اسلام، انقلاب، کشور و ملت ایران اسلامی به مبارزه با داعشیهای بیدین رفتند. حیدری گفت: شهدای مدافع حرم دنبال ریاست نبودند و آنها مانند امام حسین (ع) با خدا معامله کردند و رفتند تا ولایتفقیه تنها نماند با وجود شهدای مدافع حرم چراغ اسلام هیچگاه خاموش نمیشود. وی تصریح کرد: امام حسین توسط مسیحیها و یهودیها به شهادت نرسیدند بلکه توسط بیبصیرتهای زمان خود به شهادت رسیدند، همانهایی که پشت سر امام حسین (ع) نماز خواندند ایشان را به شهادت رساندند. وی با اشاره به اینکه دشمن با تغییر فکر جامعه زمان امام حسین (ع)، ایشان را به شهادت رساند، گفت: امروز هم دشمن با شبههافکنی، اخلاف افکنی و ایجاد بیبصیرتی در جامعه میخواهد ما را از مسیر ولایت خارج کند. حیدری گفت: شهدا رفتند دین از انحراف محفوظ بماند، رفتند تا حجاب باقی بماند، چادر از روی سر خواهران ما پایین نیاید و امنیت در کشور باقی بماند. وی بیان کرد: امام حسین (ع) در صورتی از ما عزاداری و یا سینهزنی میخواهد که نماز اول وقت خود را بخوانیم و حجاب حفظ کنیم و وظیفه همه ما در برابر شهدای جنگ تحمیلی و شهدای مدافع حرم بسیار سنگین است. مدیرکل اوقاف مازندران گفت: نیروهای سپاه و بسیج در حلقههای شجره طیبه صالحین با پیروی از فرمایشات رهبری به خوبی در حال کادرسازی هستند و از همه این نیروها و بسیجیان قدردانی میکنیم.',\n",
              " 'summary': 'مدیرکل اوقاف و امور خیریه مازندران با تاکید بر تداوم راه شهدا در جامعه دینی گفت: با وجود شهدای مدافع حرم چراغ اسلام هیچگاه خاموش نمیشود.'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dataset['train'][102]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnBHCZPvuPgp",
        "outputId": "40d544bd-2c7e-4b75-9642-1b3ce481d0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'به گزارش خبرنگار اجتماعی، الهام فخاری در جریان بیست و پنجمین جلسه شورای شهر تهران اظهار کرد: در سالهای اخیر شاهد شکلگرفتن و تثبیت غلط در مواجهه با محوطههای تاریخی بودهایم که نمونههای آن را میتوان در ساخت و سازهای غیراصولی توسط ارگانهای مختلف پیرامون مجلس شورای ملی، مسجد سپهسالار و نیز عمارت عشرتآباد مشاهده کرد. وی تصریح کرد: تلاش لازم از سوی نهادهای مسیول از جمله شهرداری برای پیشگیری از چنین خطاهای بزرگ صورت نگرفته و کار به شکل روال نادرست ادامه دارد. عضو شورای شهر تهران گفت: در این میان ساختمان بلند سازه در منظر میدان مشق و سردر باغ ملی و در ضلع غربی ساختمان پیشین روزنامه اطلاعات توسط شهرداری تهران که خود باید رکن حفاظت کننده حریم و منظر ساختمانها و محوطههای تاریخی باشد جای درنگ و تاسف دارد. فخاری افزود: از شهرداری خواسته میشود با کاستن از تعداد طبقات ساختمان اشارهشده نخستین گام را در تغییر روندهای نادرست بردارد و اصلاح امور را از نهاد مدیریتی خود بردارد. وی گفت: همچنین در مورد سازههای پیرامون میدان بهارستان و خیابان جمهوری اسلامی کاهش طبقهها و تخریب طبقههای فوقانی از الگوی معماری ایرانی اسلامی در نمای این ساختمانها متناسب با ارزشهای بافت تاریخی تهران صورت پذیرد. به گزارش تسنیم، سیدابراهیم امینی در ابتدای بیست و پنجمین جلسه شورای شهر تهران ضمن اشاره به آغاز هفته بسیج اظهار کرد: سیونهمین سالگرد تشکیل بسیثج توسط حضرت امام خمینی بنیانگذار جمهوری اسلامی ایران را گرامی میداریم و این روز را به بسیجیان فهیم و مردم عزیز ایران تبریک عرض میکنیم. وی تصریح کرد: امیدواریم با ترویج روحیه بسیج به معنای واقعی کلمه مشکلات و موانع پیش روی کشور با سربلندی پشت سر بگذاریم. امینی ضمن اشاره به حضور بسیجیان در ۸ سال دفاع مقدس اظهار کرد: آن را نمیشود فراموش کرد و هر جا و هر زمانی مردم و بسیجیان حضور داشتند توانستند خدمات شایانی را ارایه کنیم. نایبرییس شورای شهر تهران به حضور بسیجیان در منطقه زلزلهزده غرب کشور و ارایه خدمات توسط آنها اشاره کرد و گفت: این موضوع نمونه بارزی از حضور موثر بسیجیان در چنین حوادثی است. وی در پایان گفت: امیدواریم بسیجیان با سرلوحه قرار دادن سخنان حضرت امام خمینی و همچنین مقام معظم رهبری عامل به این سخنان باشند.',\n",
              " 'summary': 'عضو شورای شهر تهران گفت: ساختمان بلندسازه در منظر میدان مشق و سردر باغ ملی و در ضلع غربی ساختمان روزنامه اطلاعات توسط شهرداری در حال احداث است که این موضوع جای درنگ و تاسف دارد و درخواست میشود شهرداری از این کار جلوگیری کند.'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dataset['train'][100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZtwYlABuTDw",
        "outputId": "74ca7fbd-3d58-4081-f50f-da71e3506303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'به گزارش گروه بینالملل به نقل از رویترز سیلویو برلوسکونی نخستوزیر سابق ایتالیا به جرم کلاهبرداری مالیاتی از سوی دستگاه قضایی این کشور به ۴ سال زندان محکومشده و رای گیری سنا در خصوص آینده سیاسی وی بارها به تعویق افتاده است. بر اساس این گزارش رای گیری در خصوص اخراج برلوسکونی از سنا به چالش و بحران سیاسی دیگری برای دولت انریکو لتا نخستوزیر ایتالیا تبدیلشده است. برلوسکونی بارها تهدید کرده است که در صورت اخراج از سنا از دولت ایتلافی کنارهگیری کرده و حزب وی وزرای خود را از دولت خارج خواهد کرد. ایتالیا سومین اقتصاد بزرگ منطقه یورو به شمار میرود و با بحران بدهی ۲ هزار میلیارد یورویی روبرو است. ایتالیا با طولانیترین رکود اقتصادی پس از جنگ جهانی دوم روبرو شده است. لوییجی زاندا رهبر حزب دموکرات در سنای ایتالیا تاکید کرد، رای گیری در خصوص آینده سیاسی برلوسکونی ۲۷ نوامبر انجام خواهد شد. برلوسکونی همواره اتهامات مطرحشده بر ضد خود را رد کرده و مدعی شده که این اتهامات با اهداف سیاسی طراحیشده است.',\n",
              " 'summary': 'مقامهای رسمی ایتالیا اعلام کردند سنای این کشور ۲۷ نوامبر یعنی ۲۲ روز دیگر در خصوص اخراج نخستوزیر سابق از سنا رای گیری خواهد کرد.'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loading model and tokenizer"
      ],
      "metadata": {
        "id": "WbVrPMNqeRIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, Seq2SeqTrainingArguments"
      ],
      "metadata": {
        "id": "v1KgSER1ukxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and tokenizer\n",
        "model_name = \"m3hrdadfi/bert2bert-fa-wiki-summary\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "GVbzj9H9eXtu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "8501cbd1ff304adcbcf4f07f408078fd",
            "026adfeb4c254cafb3cceae8b614217e",
            "a83a148ed207429a9ef52e17f956dc24",
            "a8ea8751c87e482e936fb466549eace2",
            "ef9446673a9b4a31832454e9cc8ac45a",
            "aa4d3e2102794f4884d8c8538a4e5d17",
            "55e7ad5895e74f9e969f0ee29fdcfd6a",
            "0f42c7456d294dcfbde2feaa84ebf6a6",
            "9755dead87364e86b34c2eb37e95c7c3",
            "0c7c816cd9694fde9362836241bb011d",
            "ddbfb1e198784911bc9faf845d954052",
            "23d5071856a44571b409af797a79f084",
            "7d7b408d983e4077824bc91fd592230f",
            "bbaa7ea813264bbd927b15b2157bb3d3",
            "585565de366b44bd91130d1a9a2afe7e",
            "85bf69597a06482da392c74ef3306732",
            "2dfa8b4a4f024f4784d7c2cbe2100a5f",
            "44ab388b7cb2443d8ea3a96a502bc07a",
            "ff3bb7f8d4aa4f83a34c624f0466038a",
            "5d27b44724974df58f196417f7c550a5",
            "47a5130caede446c9df85e4cd5c72daa",
            "170a3887a09c4aacb6bb41c43b93ed08",
            "f3593a05031c4c60acac2528471e1217",
            "f5f1c6bdcd8e4ff6a04c944ddeb6f05f",
            "39389802cbdd459a95da812072973d17",
            "176082b7db484206b3cbea409387c785",
            "40b30e9a5ae14d84992d29b11070cac7",
            "9ed79db229f34aa4a6750aab876cd594",
            "693db38d35724d6987f2df2aeee11e90",
            "4aced287c5b34a7dbb9f50d7c9c35796",
            "38355864e4704701ae63ce0217809172",
            "90cba768282143dd8d7efd8503ef87d2",
            "89b5c39702234d8db04851668e6b400d",
            "6e857d63f12a4a0789d4c7bfbfc0efd6",
            "3e96e49d19e1414488050bb70f780157",
            "a272718dd59d431f90806327a4ea181c",
            "ec2700d9915f435ba06d0d9e9c52baed",
            "d17ae846b488492bb683211a9ed10d8a",
            "85bc3da5a92a4c2e9ea0ccd9b3eaa737",
            "3da142bd4bb944bd84b383dc4dde14a0",
            "b8f33ed66cfb4c1087eba8c191b00484",
            "9e7208de5c114440875f6d046dd7296c",
            "267ac4b21c3e46afa72ccc4c2b983869",
            "ae1c0c25ac0c4ecfa8bedf7d5a16445d",
            "822cd95f13e14124b2380316a7b61189",
            "3fb9a5aafe0745f2a5d94f1c9d9289e8",
            "b6513f2d2224457dbf822dfcc5e9587b",
            "b2c02e2f61314540a356fbd415258311",
            "a256bd34e7c14dd4a905a1cea8d8727b",
            "969d9d00119c468aa09dbdaab6ae2875",
            "80e18c195ef642008010a9f8faa04616",
            "d8a43dc5e78e42178a67733a501b34fe",
            "b3baa7457b9e46338edfe05977020ec2",
            "5e876647dc62454d8e513fe0f3ff7a0c",
            "2b0d5a6ae32e41bb9abc88fb7126fc57"
          ]
        },
        "outputId": "0a586391-b7d2-49f6-8697-f3cc8e2578d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/290 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8501cbd1ff304adcbcf4f07f408078fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23d5071856a44571b409af797a79f084"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/1.20M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3593a05031c4c60acac2528471e1217"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/172 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e857d63f12a4a0789d4c7bfbfc0efd6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "822cd95f13e14124b2380316a7b61189"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4WgjPRo_0xz",
        "outputId": "5c9d1b6e-2fe6-4268-b076-64cc30543a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): EncoderDecoderModel(\n",
              "      (encoder): BertModel(\n",
              "        (embeddings): BertEmbeddings(\n",
              "          (word_embeddings): Embedding(100000, 768, padding_idx=0)\n",
              "          (position_embeddings): Embedding(512, 768)\n",
              "          (token_type_embeddings): Embedding(2, 768)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder): BertEncoder(\n",
              "          (layer): ModuleList(\n",
              "            (0-11): 12 x BertLayer(\n",
              "              (attention): BertAttention(\n",
              "                (self): BertSelfAttention(\n",
              "                  (query): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (key): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (value): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): BertSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): BertIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): BertOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (pooler): BertPooler(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (activation): Tanh()\n",
              "        )\n",
              "      )\n",
              "      (decoder): BertLMHeadModel(\n",
              "        (bert): BertModel(\n",
              "          (embeddings): BertEmbeddings(\n",
              "            (word_embeddings): Embedding(100000, 768, padding_idx=0)\n",
              "            (position_embeddings): Embedding(512, 768)\n",
              "            (token_type_embeddings): Embedding(2, 768)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (encoder): BertEncoder(\n",
              "            (layer): ModuleList(\n",
              "              (0-11): 12 x BertLayer(\n",
              "                (attention): BertAttention(\n",
              "                  (self): BertSelfAttention(\n",
              "                    (query): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (key): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (value): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (output): BertSelfOutput(\n",
              "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                )\n",
              "                (crossattention): BertAttention(\n",
              "                  (self): BertSelfAttention(\n",
              "                    (query): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (key): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (value): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (output): BertSelfOutput(\n",
              "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                )\n",
              "                (intermediate): BertIntermediate(\n",
              "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                  (intermediate_act_fn): GELUActivation()\n",
              "                )\n",
              "                (output): BertOutput(\n",
              "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (cls): BertOnlyMLMHead(\n",
              "          (predictions): BertLMPredictionHead(\n",
              "            (transform): BertPredictionHeadTransform(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (transform_act_fn): GELUActivation()\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            )\n",
              "            (decoder): Linear(in_features=768, out_features=100000, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test model before fine-tuning"
      ],
      "metadata": {
        "id": "ae3LYnG5edba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text, max_length=150, min_length=30, num_beams=4):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, num_beams=num_beams, early_stopping=True)\n",
        "\n",
        "    # Decode and return the summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "persian_text = \"\"\"\n",
        " به گزارش گروه بین الملل ، خبرگزاری رسمی قطر اعلام کرد، بعد از امضای موافقتنامه همکاری نظامی بین قطر و روسیه این امکان فراهم شده است تا نظامیان قطری برای تکمیل آموزش‌های نظامی خود عازم روسیه شده و در آنجا تعلیم ببینند.در چارچوب این قرارداد که امروز یک شنبه توسط سرتیپ ستاد عبدالعزیز صالح السلیطی رییس هییت همکاری‌های بین المللی نظامی قطر و سرلشکر ویکتور جوریمیکین رییس اداره عمومی نیروی انسانی وزارت دفاع روسیه به امضا رسید، روابط نظامی بین دوحه و مسکو در زمینه موسسات آموزش‌های نظامی شاهد توسه قابل توجهی خواهد شد.به نوشته این خبرگزاری روابط قطر و روسیه در حال گسترش بوده و به سوی شکل‌گیری مشارکت راهبردی در تمامی زمینه‌ها پیش می‌رود.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "summary = summarize_text(persian_text)\n",
        "print(\"Original Text:\", persian_text)\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O116zu8TegCb",
        "outputId": "3af77ae5-fb10-4692-e558-fc6fa5612e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: \n",
            " به گزارش گروه بین الملل ، خبرگزاری رسمی قطر اعلام کرد، بعد از امضای موافقتنامه همکاری نظامی بین قطر و روسیه این امکان فراهم شده است تا نظامیان قطری برای تکمیل آموزش‌های نظامی خود عازم روسیه شده و در آنجا تعلیم ببینند.در چارچوب این قرارداد که امروز یک شنبه توسط سرتیپ ستاد عبدالعزیز صالح السلیطی رییس هییت همکاری‌های بین المللی نظامی قطر و سرلشکر ویکتور جوریمیکین رییس اداره عمومی نیروی انسانی وزارت دفاع روسیه به امضا رسید، روابط نظامی بین دوحه و مسکو در زمینه موسسات آموزش‌های نظامی شاهد توسه قابل توجهی خواهد شد.به نوشته این خبرگزاری روابط قطر و روسیه در حال گسترش بوده و به سوی شکل‌گیری مشارکت راهبردی در تمامی زمینه‌ها پیش می‌رود.\n",
            "\n",
            "\n",
            "Summary: روابط دیپلماتیک قطر و روسیه ( به روسی : республии руссссии ) روابط دوجانبه بین روسیه و روسیه است.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persian_text = \"\"\"\n",
        "  به گزارش خبرنگار اجتماعی، الهام فخاری در جریان بیست و پنجمین جلسه شورای شهر تهران اظهار کرد: در سالهای اخیر شاهد شکلگرفتن و تثبیت غلط در مواجهه با محوطههای تاریخی بودهایم که نمونههای آن را میتوان در ساخت و سازهای غیراصولی توسط ارگانهای مختلف پیرامون مجلس شورای ملی، مسجد سپهسالار و نیز عمارت عشرتآباد مشاهده کرد. وی تصریح کرد: تلاش لازم از سوی نهادهای مسیول از جمله شهرداری برای پیشگیری از چنین خطاهای بزرگ صورت نگرفته و کار به شکل روال نادرست ادامه دارد. عضو شورای شهر تهران گفت: در این میان ساختمان بلند سازه در منظر میدان مشق و سردر باغ ملی و در ضلع غربی ساختمان پیشین روزنامه اطلاعات توسط شهرداری تهران که خود باید رکن حفاظت کننده حریم و منظر ساختمانها و محوطههای تاریخی باشد جای درنگ و تاسف دارد. فخاری افزود: از شهرداری خواسته میشود با کاستن از تعداد طبقات ساختمان اشارهشده نخستین گام را در تغییر روندهای نادرست بردارد و اصلاح امور را از نهاد مدیریتی خود بردارد. وی گفت: همچنین در مورد سازههای پیرامون میدان بهارستان و خیابان جمهوری اسلامی کاهش طبقهها و تخریب طبقههای فوقانی از الگوی معماری ایرانی اسلامی در نمای این ساختمانها متناسب با ارزشهای بافت تاریخی تهران صورت پذیرد. به گزارش تسنیم، سیدابراهیم امینی در ابتدای بیست و پنجمین جلسه شورای شهر تهران ضمن اشاره به آغاز هفته بسیج اظهار کرد: سیونهمین سالگرد تشکیل بسیثج توسط حضرت امام خمینی بنیانگذار جمهوری اسلامی ایران را گرامی میداریم و این روز را به بسیجیان فهیم و مردم عزیز ایران تبریک عرض میکنیم. وی تصریح کرد: امیدواریم با ترویج روحیه بسیج به معنای واقعی کلمه مشکلات و موانع پیش روی کشور با سربلندی پشت سر بگذاریم. امینی ضمن اشاره به حضور بسیجیان در ۸ سال دفاع مقدس اظهار کرد: آن را نمیشود فراموش کرد و هر جا و هر زمانی مردم و بسیجیان حضور داشتند توانستند خدمات شایانی را ارایه کنیم. نایبرییس شورای شهر تهران به حضور بسیجیان در منطقه زلزلهزده غرب کشور و ارایه خدمات توسط آنها اشاره کرد و گفت: این موضوع نمونه بارزی از حضور موثر بسیجیان در چنین حوادثی است. وی در پایان گفت: امیدواریم بسیجیان با سرلوحه قرار دادن سخنان حضرت امام خمینی و همچنین مقام معظم رهبری عامل به این سخنان باشند.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "summary = summarize_text(persian_text)\n",
        "print(\"Original Text:\", persian_text)\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWYjGh6c62yA",
        "outputId": "47ebe035-e5ba-48e2-aa2b-17a3ea046d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: \n",
            "  به گزارش خبرنگار اجتماعی، الهام فخاری در جریان بیست و پنجمین جلسه شورای شهر تهران اظهار کرد: در سالهای اخیر شاهد شکلگرفتن و تثبیت غلط در مواجهه با محوطههای تاریخی بودهایم که نمونههای آن را میتوان در ساخت و سازهای غیراصولی توسط ارگانهای مختلف پیرامون مجلس شورای ملی، مسجد سپهسالار و نیز عمارت عشرتآباد مشاهده کرد. وی تصریح کرد: تلاش لازم از سوی نهادهای مسیول از جمله شهرداری برای پیشگیری از چنین خطاهای بزرگ صورت نگرفته و کار به شکل روال نادرست ادامه دارد. عضو شورای شهر تهران گفت: در این میان ساختمان بلند سازه در منظر میدان مشق و سردر باغ ملی و در ضلع غربی ساختمان پیشین روزنامه اطلاعات توسط شهرداری تهران که خود باید رکن حفاظت کننده حریم و منظر ساختمانها و محوطههای تاریخی باشد جای درنگ و تاسف دارد. فخاری افزود: از شهرداری خواسته میشود با کاستن از تعداد طبقات ساختمان اشارهشده نخستین گام را در تغییر روندهای نادرست بردارد و اصلاح امور را از نهاد مدیریتی خود بردارد. وی گفت: همچنین در مورد سازههای پیرامون میدان بهارستان و خیابان جمهوری اسلامی کاهش طبقهها و تخریب طبقههای فوقانی از الگوی معماری ایرانی اسلامی در نمای این ساختمانها متناسب با ارزشهای بافت تاریخی تهران صورت پذیرد. به گزارش تسنیم، سیدابراهیم امینی در ابتدای بیست و پنجمین جلسه شورای شهر تهران ضمن اشاره به آغاز هفته بسیج اظهار کرد: سیونهمین سالگرد تشکیل بسیثج توسط حضرت امام خمینی بنیانگذار جمهوری اسلامی ایران را گرامی میداریم و این روز را به بسیجیان فهیم و مردم عزیز ایران تبریک عرض میکنیم. وی تصریح کرد: امیدواریم با ترویج روحیه بسیج به معنای واقعی کلمه مشکلات و موانع پیش روی کشور با سربلندی پشت سر بگذاریم. امینی ضمن اشاره به حضور بسیجیان در ۸ سال دفاع مقدس اظهار کرد: آن را نمیشود فراموش کرد و هر جا و هر زمانی مردم و بسیجیان حضور داشتند توانستند خدمات شایانی را ارایه کنیم. نایبرییس شورای شهر تهران به حضور بسیجیان در منطقه زلزلهزده غرب کشور و ارایه خدمات توسط آنها اشاره کرد و گفت: این موضوع نمونه بارزی از حضور موثر بسیجیان در چنین حوادثی است. وی در پایان گفت: امیدواریم بسیجیان با سرلوحه قرار دادن سخنان حضرت امام خمینی و همچنین مقام معظم رهبری عامل به این سخنان باشند. \n",
            "\n",
            "\n",
            "\n",
            "Summary: الهام فخاری ( زاده ۱۳۳۶ در تهران ) ، معمار و فعال مدنی ایرانی است. وی دارای مدرک کارشناسی معماری از دانشکده هنرهای زیبای دانشگاه تهران و کارشناسی ارشد معماری از دانشگاه ازاد اسلامی واحد تهران مرکزی است.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dataset['train'][100]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "GVjSWV3q7qif",
        "outputId": "a4b97053-89dd-4b52-a75a-637ead9fbf87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'به گزارش گروه بینالملل به نقل از رویترز سیلویو برلوسکونی نخستوزیر سابق ایتالیا به جرم کلاهبرداری مالیاتی از سوی دستگاه قضایی این کشور به ۴ سال زندان محکومشده و رای گیری سنا در خصوص آینده سیاسی وی بارها به تعویق افتاده است. بر اساس این گزارش رای گیری در خصوص اخراج برلوسکونی از سنا به چالش و بحران سیاسی دیگری برای دولت انریکو لتا نخستوزیر ایتالیا تبدیلشده است. برلوسکونی بارها تهدید کرده است که در صورت اخراج از سنا از دولت ایتلافی کنارهگیری کرده و حزب وی وزرای خود را از دولت خارج خواهد کرد. ایتالیا سومین اقتصاد بزرگ منطقه یورو به شمار میرود و با بحران بدهی ۲ هزار میلیارد یورویی روبرو است. ایتالیا با طولانیترین رکود اقتصادی پس از جنگ جهانی دوم روبرو شده است. لوییجی زاندا رهبر حزب دموکرات در سنای ایتالیا تاکید کرد، رای گیری در خصوص آینده سیاسی برلوسکونی ۲۷ نوامبر انجام خواهد شد. برلوسکونی همواره اتهامات مطرحشده بر ضد خود را رد کرده و مدعی شده که این اتهامات با اهداف سیاسی طراحیشده است.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dataset['train'][100]['summary']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7MVqOgMQ7wiL",
        "outputId": "8d2e8b07-27db-4379-9017-65ad2ae97865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'مقامهای رسمی ایتالیا اعلام کردند سنای این کشور ۲۷ نوامبر یعنی ۲۲ روز دیگر در خصوص اخراج نخستوزیر سابق از سنا رای گیری خواهد کرد.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persian_text =  clean_dataset['train'][100]['text']\n",
        "\n",
        "summary = summarize_text(persian_text)\n",
        "print(\"Original Text:\", persian_text)\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGiIYDUx7jci",
        "outputId": "5b165706-10da-442b-ec55-ed7a9dc18d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: به گزارش گروه بینالملل به نقل از رویترز سیلویو برلوسکونی نخستوزیر سابق ایتالیا به جرم کلاهبرداری مالیاتی از سوی دستگاه قضایی این کشور به ۴ سال زندان محکومشده و رای گیری سنا در خصوص آینده سیاسی وی بارها به تعویق افتاده است. بر اساس این گزارش رای گیری در خصوص اخراج برلوسکونی از سنا به چالش و بحران سیاسی دیگری برای دولت انریکو لتا نخستوزیر ایتالیا تبدیلشده است. برلوسکونی بارها تهدید کرده است که در صورت اخراج از سنا از دولت ایتلافی کنارهگیری کرده و حزب وی وزرای خود را از دولت خارج خواهد کرد. ایتالیا سومین اقتصاد بزرگ منطقه یورو به شمار میرود و با بحران بدهی ۲ هزار میلیارد یورویی روبرو است. ایتالیا با طولانیترین رکود اقتصادی پس از جنگ جهانی دوم روبرو شده است. لوییجی زاندا رهبر حزب دموکرات در سنای ایتالیا تاکید کرد، رای گیری در خصوص آینده سیاسی برلوسکونی ۲۷ نوامبر انجام خواهد شد. برلوسکونی همواره اتهامات مطرحشده بر ضد خود را رد کرده و مدعی شده که این اتهامات با اهداف سیاسی طراحیشده است.\n",
            "Summary: بنیتو موسولینی ( به ایتالیایی : بنیتو موسولینی ) ( زاده ۲۷ نوامبر ۱۹۲۶ در شهر میلان ) سیاستمدار ایتالیایی و ريیس کمیسیون اروپا و امور خارجی سازمان ملل متحد است. او از سال ۲۰۱۱ تا سال ۲۰۱۷ ریاست کمیسیون اروپا اروپا را برعهده داشت. موسولینی از سال ۲۰۰۶ تا ۲۰۱۱ وزیر امور خارجه ایتالیا بود و از سال ۲۰۰۷ تا ۲۰۱۱ به مدت دو سال به عنوان وزیر امور اروپا فعالیت میکرد. وی از سال ۲۰۱۲ تا ۲۰۱۳ به مدت یک سال ، از سال ۲۰۱۴ تا سال ۲۰۱۹ به عنوان عضو کمیسیون اروپا به عضویت این کمیسیون در امد.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1X3jlye73KZ",
        "outputId": "611f6257-53e3-464d-c2b6-61b7fca88a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: بنیتو موسولینی ( به ایتالیایی : بنیتو موسولینی ) ( زاده ۲۷ نوامبر ۱۹۲۶ در شهر میلان ) سیاستمدار ایتالیایی و ريیس کمیسیون اروپا و امور خارجی سازمان ملل متحد است. او از سال ۲۰۱۱ تا سال ۲۰۱۷ ریاست کمیسیون اروپا اروپا را برعهده داشت. موسولینی از سال ۲۰۰۶ تا ۲۰۱۱ وزیر امور خارجه ایتالیا بود و از سال ۲۰۰۷ تا ۲۰۱۱ به مدت دو سال به عنوان وزیر امور اروپا فعالیت میکرد. وی از سال ۲۰۱۲ تا ۲۰۱۳ به مدت یک سال ، از سال ۲۰۱۴ تا سال ۲۰۱۹ به عنوان عضو کمیسیون اروپا به عضویت این کمیسیون در امد.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persian_text =  clean_dataset['train'][0]['text']\n",
        "\n",
        "summary = summarize_text(persian_text)\n",
        "\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn1K1Uei_j_Q",
        "outputId": "17618fd6-2d63-4c88-e464-d4a5473fa823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: سید محمد اسلامی ( زاده ۱۳۳۸ ، کرمانشاه ) ، نماینده مردم کرمانشاه در مجلس شورای اسلامی از استان کرمانشاه است. وی دارای مدرک دکترای علوم سیاسی از دانشگاه ازاد اسلامی واحد علوم و تحقیقات تهران است. اسلامی در حال حاضر ريیس هیيت مدیره شرکت توسعه صادرات ایران است.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dataset['train'][0]['summary']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Sr-EhePCJAMj",
        "outputId": "47e02adc-bbc9-4a80-d248-01a913262f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'وزیر راه و شهرسازی از فعال بودن ۲۵ پایانه مرزی کشور خبر داد و گفت: ۶۰ درصد از روابط تجاری ایران از طریق این پایانه انجام میشود.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persian_text =  clean_dataset['train'][1]['text']\n",
        "\n",
        "summary = summarize_text(persian_text)\n",
        "\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SNg7cnp_r-K",
        "outputId": "677d6bf9-8f66-4d71-cb27-c34aa1572d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: ابراهیم حیدری فرزند ابراهیم حیدری ، از فرماندهان سپاه پاسداران انقلاب اسلامی در جنگ ایران و عراق بود. او از فرماندهان ارشد سپاه پاسداران در دفاع مقدس و دفاع مقدس بود و در جنگ با عراق نقش مهمی ایفا کرد.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persian_text =  clean_dataset['train'][102]['text']\n",
        "\n",
        "summary = summarize_text(persian_text)\n",
        "\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMptM2tj_vCj",
        "outputId": "faae8762-b141-4410-e8d7-544f9972d8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: الهام فخاری ( زاده ۱۳۳۶ در تهران ) ، معمار و فعال مدنی ایرانی است. وی دارای مدرک کارشناسی معماری از دانشکده هنرهای زیبای دانشگاه تهران و کارشناسی ارشد معماری از دانشگاه ازاد اسلامی واحد تهران مرکزی است.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dataset['train'][102]['summary']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wFxeAVN9JJhb",
        "outputId": "7e7acf9b-dab1-4724-de5d-ce5431856f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'عضو شورای شهر تهران گفت: ساختمان بلندسازه در منظر میدان مشق و سردر باغ ملی و در ضلع غربی ساختمان روزنامه اطلاعات توسط شهرداری در حال احداث است که این موضوع جای درنگ و تاسف دارد و درخواست میشود شهرداری از این کار جلوگیری کند.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocess the dataset"
      ],
      "metadata": {
        "id": "azH1zOEIepn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the dataset\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples['text']\n",
        "    targets = examples['summary']\n",
        "    model_inputs = tokenizer(inputs, max_length=256, truncation=True, padding='max_length')  # Truncate input length\n",
        "    labels = tokenizer(targets, max_length=64, truncation=True, padding='max_length')       # Truncate label length\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "# Ensure correct formatting\n",
        "def format_dataset(example):\n",
        "    example['input_ids'] = [int(x) for x in example['input_ids']]\n",
        "    example['labels'] = [int(x) for x in example['labels']]\n",
        "    return example"
      ],
      "metadata": {
        "id": "TFou9b48ejqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here I tokenize both my text and summary to be ready to be feed to model\n",
        "tokenized_datasets_train = clean_dataset['train'].map(preprocess_function, batched=False, remove_columns=['text', 'summary'])\n",
        "\n",
        "tokenized_datasets_eval = clean_dataset['validation'].map(preprocess_function, batched=False, remove_columns=['text', 'summary'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e90a5766d7734500b5e423b34e04a0a8",
            "ae772451a6a34b24994e2d5784ea353f",
            "ba567ee5a0664541b3d75fce4d03e828",
            "a480893e351142a380eaebe1621e642d",
            "47c8d29a11934580ad726c661c49a806",
            "ed4a9d82ed674bd68278decf0831f39f",
            "54c6688915ed4e818ca33d1d7d783a7d",
            "a2a0ac7ba93841cdb90579f993fbb936",
            "5fd5c916fd99411795fbdf4f9fb8ce89",
            "9aac9115b9494ba69b6930031ab931c4",
            "d5a80290b4b34125a8bc4f2835e33a9d",
            "fdec1294f32b4562b5166824095fc8a5",
            "afdf55f5d84e49599c5fec52e24312b1",
            "80ebf14566084f789a5ebb6f2c4e6fab",
            "089b43f15c4a4f1b8e31eef1bd259cd6",
            "3b6a7b84cf1642d1beab5b61df18a8b9",
            "88d01b838e0c4bc8953f7ff9d9700a51",
            "161ebe32ffbb47b4abd468149546f2c1",
            "bf47430fd7ad46b3ba6511d9910f2037",
            "425b74f1ff0e46a8b726ca20836d1770",
            "004b15350d2547a88dd3032d077b4234",
            "b40164861a48489e9e474a002a14a7b6"
          ]
        },
        "id": "OuRdluuYeuD3",
        "outputId": "c2f27e69-dab3-4899-a569-ef5510fa3ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e90a5766d7734500b5e423b34e04a0a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdec1294f32b4562b5166824095fc8a5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxO9vK-Y_7V7",
        "outputId": "556a65a8-c382-42f7-c2ef-a92d0380d701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 500\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fine-tuning"
      ],
      "metadata": {
        "id": "6SmBZHKAe2Uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, EncoderDecoderModel, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType"
      ],
      "metadata": {
        "id": "xgD2BMv6e3iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/peft\n",
        "!cd peft\n",
        "!pip install peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rhUN3Pd98TTB",
        "outputId": "fbb63ccc-294d-4562-8cb0-05ca9b2b5d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'peft' already exists and is not an empty directory.\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.43.0.dev0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from peft) (0.32.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->peft) (0.23.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "IKWKDh_nJekR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QLoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "    inference_mode=False,\n",
        "    r=4,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"query\", \"key\", \"value\"]\n",
        "\n",
        ")\n",
        "\n",
        "# Prepare model for QLoRA training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/planA/resultsplanA\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=2,  # Reduce batch size further\n",
        "    per_device_eval_batch_size=2,   # Reduce batch size further\n",
        "    num_train_epochs=30,             # Keep the number of epochs low\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    gradient_accumulation_steps=4,  # Use gradient accumulation to simulate a larger batch size\n",
        "    fp16=True,  # Use mixed precision training\n",
        ")\n",
        "\n",
        "# Define a simple compute metrics function\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define a function to compute evaluation metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # If predictions is a tuple, assume it contains logits and not yet processed predictions\n",
        "    if isinstance(predictions, tuple):\n",
        "        predictions = predictions[0]  # Extract the logits from the tuple\n",
        "\n",
        "    # Get predicted ids by choosing the highest logit score\n",
        "    predictions = predictions.argmax(axis=-1)\n",
        "\n",
        "    # Flatten labels and predictions for accuracy calculation\n",
        "    labels_flat = labels.flatten()\n",
        "    predictions_flat = predictions.flatten()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(labels_flat, predictions_flat)\n",
        "\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets_train,\n",
        "    eval_dataset=tokenized_datasets_eval,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model, tokenizer, and training arguments\n",
        "# Save the model and tokenizer\n",
        "model.save_pretrained(\"/content/drive/MyDrive/planA/resultsplanA\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/planA/resultsplanA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GEGkZwnFe4O4",
        "outputId": "a46a699b-062c-4bdc-ca71-24da6882953f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1524: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1852' max='1860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1852/1860 25:06 < 00:06, 1.23 it/s, Epoch 29.62/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>11.240900</td>\n",
              "      <td>11.442754</td>\n",
              "      <td>0.142187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>8.063900</td>\n",
              "      <td>7.025790</td>\n",
              "      <td>0.143125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.643700</td>\n",
              "      <td>3.296130</td>\n",
              "      <td>0.608750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.845500</td>\n",
              "      <td>2.646617</td>\n",
              "      <td>0.636250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.477400</td>\n",
              "      <td>2.415870</td>\n",
              "      <td>0.650625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.424300</td>\n",
              "      <td>2.320270</td>\n",
              "      <td>0.656563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.309100</td>\n",
              "      <td>2.259420</td>\n",
              "      <td>0.659062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.211200</td>\n",
              "      <td>2.211772</td>\n",
              "      <td>0.660625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>2.296900</td>\n",
              "      <td>2.175114</td>\n",
              "      <td>0.660937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.084500</td>\n",
              "      <td>2.147094</td>\n",
              "      <td>0.662813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.085400</td>\n",
              "      <td>2.125311</td>\n",
              "      <td>0.662813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>2.312300</td>\n",
              "      <td>2.109295</td>\n",
              "      <td>0.663750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>2.053500</td>\n",
              "      <td>2.097719</td>\n",
              "      <td>0.665625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.983000</td>\n",
              "      <td>2.090539</td>\n",
              "      <td>0.665937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>2.000600</td>\n",
              "      <td>2.087111</td>\n",
              "      <td>0.665312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1861' max='1860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1860/1860 25:12, Epoch 29.76/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>11.240900</td>\n",
              "      <td>11.442754</td>\n",
              "      <td>0.142187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>8.063900</td>\n",
              "      <td>7.025790</td>\n",
              "      <td>0.143125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.643700</td>\n",
              "      <td>3.296130</td>\n",
              "      <td>0.608750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.845500</td>\n",
              "      <td>2.646617</td>\n",
              "      <td>0.636250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.477400</td>\n",
              "      <td>2.415870</td>\n",
              "      <td>0.650625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.424300</td>\n",
              "      <td>2.320270</td>\n",
              "      <td>0.656563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.309100</td>\n",
              "      <td>2.259420</td>\n",
              "      <td>0.659062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.211200</td>\n",
              "      <td>2.211772</td>\n",
              "      <td>0.660625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>2.296900</td>\n",
              "      <td>2.175114</td>\n",
              "      <td>0.660937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.084500</td>\n",
              "      <td>2.147094</td>\n",
              "      <td>0.662813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.085400</td>\n",
              "      <td>2.125311</td>\n",
              "      <td>0.662813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>2.312300</td>\n",
              "      <td>2.109295</td>\n",
              "      <td>0.663750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>2.053500</td>\n",
              "      <td>2.097719</td>\n",
              "      <td>0.665625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.983000</td>\n",
              "      <td>2.090539</td>\n",
              "      <td>0.665937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>2.000600</td>\n",
              "      <td>2.087111</td>\n",
              "      <td>0.665312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/planA/resultsplanA\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/planA/resultsplanA\")"
      ],
      "metadata": {
        "id": "r--ZcoDp-vCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d74399d6-10e4-4de1-86f5-05215a923f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/planA/resultsplanA/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/planA/resultsplanA/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/planA/resultsplanA/vocab.txt',\n",
              " '/content/drive/MyDrive/planA/resultsplanA/added_tokens.json',\n",
              " '/content/drive/MyDrive/planA/resultsplanA/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# inference"
      ],
      "metadata": {
        "id": "Gq-6H5qJe9ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import  AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "BP5Zg_O6e-bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6vWBKZ3vjA9C",
        "outputId": "d495286d-6661-4727-ccd9-c33a4be7c35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'m3hrdadfi/bert2bert-fa-wiki-summary'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"m3hrdadfi/bert2bert-fa-wiki-summary\"\n",
        "# Load the entire model on the GPU 0\n",
        "device_map = {\"\": 0}\n",
        "# fine-tuned model path\n",
        "output_dir = \"/content/drive/MyDrive/planA/resultsplanA\"\n",
        "\n",
        "# because I am using lora I need to use PeftModel to have my base model and fine-tuned model\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "model = PeftModel.from_pretrained(base_model, output_dir)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
      ],
      "metadata": {
        "id": "CFbZSPsyfAop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z1xMedjRi2nP",
        "outputId": "1e39f61a-f2c7-44af-b0b0-69c71334fe97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): EncoderDecoderModel(\n",
              "      (encoder): BertModel(\n",
              "        (embeddings): BertEmbeddings(\n",
              "          (word_embeddings): Embedding(100000, 768, padding_idx=0)\n",
              "          (position_embeddings): Embedding(512, 768)\n",
              "          (token_type_embeddings): Embedding(2, 768)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder): BertEncoder(\n",
              "          (layer): ModuleList(\n",
              "            (0-11): 12 x BertLayer(\n",
              "              (attention): BertAttention(\n",
              "                (self): BertSelfAttention(\n",
              "                  (query): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (key): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (value): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): BertSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): BertIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): BertOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (pooler): BertPooler(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (activation): Tanh()\n",
              "        )\n",
              "      )\n",
              "      (decoder): BertLMHeadModel(\n",
              "        (bert): BertModel(\n",
              "          (embeddings): BertEmbeddings(\n",
              "            (word_embeddings): Embedding(100000, 768, padding_idx=0)\n",
              "            (position_embeddings): Embedding(512, 768)\n",
              "            (token_type_embeddings): Embedding(2, 768)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (encoder): BertEncoder(\n",
              "            (layer): ModuleList(\n",
              "              (0-11): 12 x BertLayer(\n",
              "                (attention): BertAttention(\n",
              "                  (self): BertSelfAttention(\n",
              "                    (query): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (key): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (value): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (output): BertSelfOutput(\n",
              "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                )\n",
              "                (crossattention): BertAttention(\n",
              "                  (self): BertSelfAttention(\n",
              "                    (query): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (key): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (value): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=4, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=4, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (output): BertSelfOutput(\n",
              "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                )\n",
              "                (intermediate): BertIntermediate(\n",
              "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                  (intermediate_act_fn): GELUActivation()\n",
              "                )\n",
              "                (output): BertOutput(\n",
              "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (cls): BertOnlyMLMHead(\n",
              "          (predictions): BertLMPredictionHead(\n",
              "            (transform): BertPredictionHeadTransform(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (transform_act_fn): GELUActivation()\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            )\n",
              "            (decoder): Linear(in_features=768, out_features=100000, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## after 1 epoc\n"
      ],
      "metadata": {
        "id": "MVvuyXajBBB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to get input text, tokenize it and give it to model for summarization\n",
        "def summarize_text(text, max_length=150, min_length=30, num_beams=4):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(input_ids=inputs, max_length=max_length, min_length=min_length, num_beams=num_beams, early_stopping=True)\n",
        "\n",
        "    # Decode and return the summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "persian_text = \"\"\"\n",
        " به گزارش گروه بین الملل ، خبرگزاری رسمی قطر اعلام کرد، بعد از امضای موافقتنامه همکاری نظامی بین قطر و روسیه این امکان فراهم شده است تا نظامیان قطری برای تکمیل آموزش‌های نظامی خود عازم روسیه شده و در آنجا تعلیم ببینند.در چارچوب این قرارداد که امروز یک شنبه توسط سرتیپ ستاد عبدالعزیز صالح السلیطی رییس هییت همکاری‌های بین المللی نظامی قطر و سرلشکر ویکتور جوریمیکین رییس اداره عمومی نیروی انسانی وزارت دفاع روسیه به امضا رسید، روابط نظامی بین دوحه و مسکو در زمینه موسسات آموزش‌های نظامی شاهد توسه قابل توجهی خواهد شد.به نوشته این خبرگزاری روابط قطر و روسیه در حال گسترش بوده و به سوی شکل‌گیری مشارکت راهبردی در تمامی زمینه‌ها پیش می‌رود.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "summary = summarize_text(persian_text)\n",
        "print(\"Original Text:\", persian_text)\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TrjilcGfFga",
        "outputId": "fc2272e4-6cc1-43a2-e50f-aba0975937bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: \n",
            " به گزارش گروه بین الملل ، خبرگزاری رسمی قطر اعلام کرد، بعد از امضای موافقتنامه همکاری نظامی بین قطر و روسیه این امکان فراهم شده است تا نظامیان قطری برای تکمیل آموزش‌های نظامی خود عازم روسیه شده و در آنجا تعلیم ببینند.در چارچوب این قرارداد که امروز یک شنبه توسط سرتیپ ستاد عبدالعزیز صالح السلیطی رییس هییت همکاری‌های بین المللی نظامی قطر و سرلشکر ویکتور جوریمیکین رییس اداره عمومی نیروی انسانی وزارت دفاع روسیه به امضا رسید، روابط نظامی بین دوحه و مسکو در زمینه موسسات آموزش‌های نظامی شاهد توسه قابل توجهی خواهد شد.به نوشته این خبرگزاری روابط قطر و روسیه در حال گسترش بوده و به سوی شکل‌گیری مشارکت راهبردی در تمامی زمینه‌ها پیش می‌رود.\n",
            "\n",
            "\n",
            "Summary: روابط دیپلماتیک قطر و روسیه ( به روسی : республии руссссии ) روابط دوجانبه بین روسیه و روسیه است.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persian_text =  clean_dataset['train'][100]['text']\n",
        "\n",
        "summary = summarize_text(persian_text)\n",
        "\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5BYFi9-Alga",
        "outputId": "f7d453df-b1ee-4dc6-842b-a3a11d74838e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: بنیتو موسولینی ( به ایتالیایی : بنیتو موسولینی ) ( زاده ۲۷ نوامبر ۱۹۲۶ در شهر میلان ) سیاستمدار ایتالیایی و ريیس کمیسیون اروپا و امور خارجی سازمان ملل متحد است. او از سال ۲۰۱۱ تا سال ۲۰۱۷ ریاست کمیسیون اروپا اروپا را برعهده داشت. موسولینی از سال ۲۰۰۶ تا ۲۰۱۱ وزیر امور خارجه ایتالیا بود و از سال ۲۰۰۷ تا ۲۰۱۱ به مدت دو سال به عنوان وزیر امور اروپا فعالیت میکرد. وی از سال ۲۰۱۲ تا ۲۰۱۳ به مدت یک سال ، از سال ۲۰۱۴ تا سال ۲۰۱۹ به عنوان عضو کمیسیون اروپا به عضویت این کمیسیون در امد.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dataset['train'][100]['summary']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dnB6h3Q6Ay7_",
        "outputId": "bc253fa2-1ee6-4f52-fb32-715d19c0ea1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'مقامهای رسمی ایتالیا اعلام کردند سنای این کشور ۲۷ نوامبر یعنی ۲۲ روز دیگر در خصوص اخراج نخستوزیر سابق از سنا رای گیری خواهد کرد.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zN2TLlKXA3qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# after 30 epoc"
      ],
      "metadata": {
        "id": "QAAZDNNmBG4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to get input text, tokenize it and give it to model for summarization\n",
        "def summarize_text(text, max_length=150, min_length=30, num_beams=4):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(input_ids=inputs, max_length=max_length, min_length=min_length, num_beams=num_beams, early_stopping=True)\n",
        "\n",
        "    # Decode and return the summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "1oKTonbDd-gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# improvment\n",
        "persian_text =  clean_dataset['train'][0]['text']\n",
        "\n",
        "summary = summarize_text(persian_text)\n",
        "\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbF-uXdJPk2Z",
        "outputId": "a13c658a-d411-459f-c819-8f49f64f5681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: وزیر تعاون ، کار و رفاه اجتماعی جمهوری اسلامی ایران گفت : در حال حاضر بیش از ۴۰ هزار نفر در استانهای مرزی و مرزی در حال انجام است که از این تعداد حدود ۳۵۰ هزار نفر نفر در حال فعالیت هستند.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persian_text =  clean_dataset['train'][1]['text']\n",
        "\n",
        "summary = summarize_text(persian_text)\n",
        "\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-RyJEn6QAUc",
        "outputId": "eee4d566-00fb-4517-c716-541fac490d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: مدیرکل اوقاف و امور خیریه سپاه پاسداران مازندران گفت : در حال حاضر تعداد زیادی از شهدای سپاه پاسداران جان خود را از دست دادهاند. وی در خصوص اینکه ایا این شهدا در حال انجام است یا خیر ، گفت : « به خاطر اینکه شهدا در یک صف صف بودند ». در طول جنگ ایران و عراق و در جریان جنگ هشت ساله ، صدها تن از نیروهای سپاه پاسداران کشته شدند و دهها تن دیگر نیز زخمی شدند.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persian_text =  clean_dataset['train'][102]['text']\n",
        "\n",
        "summary = summarize_text(persian_text)\n",
        "\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRfMo_xfQl2G",
        "outputId": "c7235af9-cab6-4df3-f632-a2508280f9e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: سابق و دبیر شورای چهارم شورای اسلامی شهر تهران گفت : در این دوره از انتخابات شورای شهر تهران و در جریان برگزاری انتخابات شورای چهارم ، شورای چهارم و پنجم تهران برای انتخاب اعضای شورای شهر و تعیین شهردار جدید تهران و نظارت بر عملکرد این شورا ، اقدام به برگزاری انتخابات کردند که در نهایت منجر به پیروزی این شورا شد.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PZ7fMw7FQ3D9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}